package md2pdf

import (
	"runtime"
	"sync"
	"testing"
	"time"
)

// Compile-time interface check.
var _ interface {
	Acquire() *Service
	Release(*Service)
	Size() int
	Close() error
} = (*ServicePool)(nil)

func TestResolvePoolSize(t *testing.T) {
	t.Parallel()

	gomaxprocs := runtime.GOMAXPROCS(0)

	tests := []struct {
		name    string
		workers int
		want    int
	}{
		{
			name:    "explicit takes priority",
			workers: 4,
			want:    4,
		},
		{
			name:    "explicit=1 for sequential",
			workers: 1,
			want:    1,
		},
		{
			name:    "zero uses auto calculation",
			workers: 0,
			want:    min(max(gomaxprocs/cpuDivisor, MinPoolSize), MaxPoolSize),
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			t.Parallel()

			got := ResolvePoolSize(tt.workers)
			if got != tt.want {
				t.Errorf("ResolvePoolSize(%d) = %d, want %d", tt.workers, got, tt.want)
			}
		})
	}
}

func TestResolvePoolSize_Bounds(t *testing.T) {
	t.Parallel()

	t.Run("minimum is 1", func(t *testing.T) {
		t.Parallel()

		got := ResolvePoolSize(0)
		if got < MinPoolSize {
			t.Errorf("ResolvePoolSize(0) = %d, should be at least %d", got, MinPoolSize)
		}
	})

	t.Run("maximum is 8", func(t *testing.T) {
		t.Parallel()

		got := ResolvePoolSize(0)
		if got > MaxPoolSize {
			t.Errorf("ResolvePoolSize(0) = %d, should be at most %d", got, MaxPoolSize)
		}
	})

	t.Run("explicit can exceed max", func(t *testing.T) {
		t.Parallel()

		got := ResolvePoolSize(16)
		if got != 16 {
			t.Errorf("ResolvePoolSize(16) = %d, want 16", got)
		}
	})
}

func TestServicePool_AcquireRelease(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(2)
	defer pool.Close()

	// Acquire first service
	svc1 := pool.Acquire()
	if svc1 == nil {
		t.Fatal("Acquire() returned nil")
	}

	// Acquire second service
	svc2 := pool.Acquire()
	if svc2 == nil {
		t.Fatal("Acquire() returned nil")
	}

	// Services should be different instances
	if svc1 == svc2 {
		t.Error("expected different service instances")
	}

	// Release and re-acquire
	pool.Release(svc1)
	svc3 := pool.Acquire()

	if svc3 != svc1 {
		t.Error("expected to get back released service")
	}

	// Cleanup
	pool.Release(svc2)
	pool.Release(svc3)
}

func TestServicePool_Size(t *testing.T) {
	t.Parallel()

	tests := []struct {
		name string
		size int
		want int
	}{
		{"size 1", 1, 1},
		{"size 4", 4, 4},
		{"size 0 becomes 1", 0, 1},
		{"negative becomes 1", -1, 1},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			t.Parallel()

			pool := NewServicePool(tt.size)
			defer pool.Close()

			if got := pool.Size(); got != tt.want {
				t.Errorf("Size() = %d, want %d", got, tt.want)
			}
		})
	}
}

func TestServicePool_ConcurrentAccess(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(4)
	defer pool.Close()

	var wg sync.WaitGroup
	iterations := 20

	for i := 0; i < iterations; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			svc := pool.Acquire()
			time.Sleep(5 * time.Millisecond) // Simulate work
			pool.Release(svc)
		}()
	}

	// Should complete without deadlock
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()

	timer := time.NewTimer(5 * time.Second)
	defer timer.Stop()

	select {
	case <-done:
		// Success
	case <-timer.C:
		t.Fatal("concurrent access test timed out - possible deadlock")
	}
}

func TestServicePool_ClosePreventsFurtherRelease(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(2)

	svc := pool.Acquire()
	pool.Close()

	// Release after close should not panic
	pool.Release(svc) // Should be safe (no-op)
}

func TestServicePool_DoubleClose(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(1)

	// First close
	if err := pool.Close(); err != nil {
		t.Errorf("first Close() error = %v", err)
	}

	// Second close should not panic
	pool.Close()
}

func TestServicePool_AcquireAfterClose(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(2)

	// Acquire one service
	svc := pool.Acquire()
	if svc == nil {
		t.Fatal("Acquire() returned nil")
	}

	// Close the pool
	pool.Close()

	// Release should not panic after close
	pool.Release(svc)

	// Note: Acquire after close will block forever on empty channel,
	// so we don't test that directly - it's documented behavior.
}

func TestServicePool_ReleaseNilService(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(1)
	defer pool.Close()

	// Acquire to create a service
	svc := pool.Acquire()
	pool.Release(svc)

	// Release nil should cause panic (channel send on nil),
	// but this is expected behavior - callers should not release nil.
	// This test documents that behavior.
}

// TestServicePool_HighContention verifies the pool remains deadlock-free under
// heavy concurrent access. A small pool (2 services) with many goroutines (50)
// each performing multiple acquire/release cycles exposes race conditions and
// channel blocking issues that wouldn't surface with lighter loads.
func TestServicePool_HighContention(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(2)
	defer pool.Close()

	var wg sync.WaitGroup
	goroutines := 50
	iterations := 10

	for i := 0; i < goroutines; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for j := 0; j < iterations; j++ {
				svc := pool.Acquire()
				// Simulate variable work duration
				time.Sleep(time.Duration(j%3) * time.Millisecond)
				pool.Release(svc)
			}
		}()
	}

	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()

	timer := time.NewTimer(30 * time.Second)
	defer timer.Stop()

	select {
	case <-done:
		// Success - no deadlock under high contention
	case <-timer.C:
		t.Fatal("high contention test timed out - possible deadlock")
	}
}

func TestServicePool_AllServicesAcquired(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(3)
	defer pool.Close()

	// Acquire all services
	services := make([]*Service, 3)
	for i := 0; i < 3; i++ {
		services[i] = pool.Acquire()
		if services[i] == nil {
			t.Fatalf("Acquire() returned nil for service %d", i)
		}
	}

	// Verify we got 3 distinct services
	seen := make(map[*Service]bool)
	for _, svc := range services {
		if seen[svc] {
			t.Error("got duplicate service from pool")
		}
		seen[svc] = true
	}

	// Release all
	for _, svc := range services {
		pool.Release(svc)
	}
}

func TestServicePool_LazyCreation(t *testing.T) {
	t.Parallel()

	pool := NewServicePool(3)
	defer pool.Close()

	// Pool should not create services until acquired
	// Acquire one service
	svc1 := pool.Acquire()
	if svc1 == nil {
		t.Fatal("first Acquire() returned nil")
	}

	// Release it
	pool.Release(svc1)

	// Acquire again - should get the same service (reuse)
	svc2 := pool.Acquire()
	if svc2 != svc1 {
		t.Error("expected to reuse released service")
	}

	pool.Release(svc2)
}

func TestResolvePoolSize_NegativeWorkers(t *testing.T) {
	t.Parallel()

	// Negative workers should be treated as 0 (auto-calculate)
	got := ResolvePoolSize(-5)

	if got < MinPoolSize || got > MaxPoolSize {
		t.Errorf("ResolvePoolSize(-5) = %d, should be between %d and %d", got, MinPoolSize, MaxPoolSize)
	}
}

func TestResolvePoolSize_LargeExplicitValue(t *testing.T) {
	t.Parallel()

	// Explicit value above MaxPoolSize should be allowed
	got := ResolvePoolSize(100)

	if got != 100 {
		t.Errorf("ResolvePoolSize(100) = %d, want 100", got)
	}
}
